import csv
import numpy as np
import re
import pandas as pd        
from pandas import *
        
def get_design_np(fname):
    raw = pd.read_csv(fname, sep = ",")
    ret = np.asarray(raw.values, dtype = 'a1000')

    return ret

design_data = get_design_np('design_file.csv')

df_design = DataFrame(design_data)
"""
Modifcation history - 12/13/14
Description: fixing the file read input
Once the file reader was changed from 
    
    
"""

refseq = list(design_data[:,3])
ID = list(design_data[:,0])
Name = list(design_data[:,1])
Row = list(design_data[:,4])
Column = list(design_data[:,5])
Feature_number = list(design_data[:,6])
Mapping_quality_designs = list(design_data[:,9])
Chromosome_Coordinates_designs = list(design_data[:,10])

def get_sam_np(fname):  # function name and filename argument
    raw = pd.read_csv(fname, sep = ",")
    ret = np.asarray(raw.values, dtype = 'a5000')
    

    return ret
    
sam_data = get_sam_np('EasyNGS_Sam.csv')

df_sam = DataFrame(sam_data)

chromosome = list(df_sam[2])
position = list(df_sam[3])
read_seq = list(df_sam[9])
chromosome_coordinates = list(DataFrame(np.array(np.transpose((chromosome[:], position[:])))))
CIGAR = list(df_sam[5])

index = 0

"""
Author: Alok Subbarao
MODIFICATION HISTORY: 12/2/2014
DESCRIPTION: Updated the part of the code that analyzes the SAM file
to calculate insertions and deletions. Prior function below.

index = 0
for each in CIGAR[index]:
    present_cigar = CIGAR[index]
    indels = re.findall('(\d+[ID])', present_cigar)
    for num1, i_or_d in indels :
        print 'Number of indels:' , num1, i_or_d 
        print indels.span()
    index += 1
    
    
    
"""
indels = re.compile('\d+[ID]')

def hasindel(element):
    """
    Description: searches a string for any digit followed by "I" or "D" to 
    determine whether the string contains indels or deletions
    
    Postconditions: Returns either 'true' or 'false'
    
    Side effects: none
    
    Return: True if an indel is present, otherwise false
     """
    if indels.search(element): #this will return true if it is found otherwise none
         return True
    else:
         return False

index = 0
indel_loc =[] #contains index of indels in CIGAR
indel_span = [] #the span of the indels within CIGAR[index]
indel_type = [] #list of strings containing the actual indel
total_indel_info=[] #metalist of the above 3 lists

for index in enumerate(CIGAR): 
    if hasindel(index[1]): 
        indel_loc.append(index[0]) #if the item has an indel, append the  location 
        
for x in indel_loc:
    present_cigar =  indels.finditer(CIGAR[x]) #create iterator, use regex to store the span and group
    for y in present_cigar:
        indel_span.append(y.span())
        indel_type.append(y.group())
        
for q in range(len(indel_loc)):
    total_indel_info.insert(q,((indel_loc[q], indel_type[q], indel_span[q]))) #merge the created lists into one list

insertions = 0
deletions = 0
for i_or_d in indel_type:
    if i_or_d[1] == "I":
        insertions += int(i_or_d[0])
    elif i_or_d[1] == "D":
        deletions += int(i_or_d[0]) 
        #calculates number of specific indels and deletionos
        
"""
End of edit from ngs_summary_jeff by A.Subbarao 12/2/2014
"""

#####deletions just returns the length of indel_type (doesn't seem to differentiate between I or D). I think indexing of loop is incorrect        


    
 

        


def get_mpileup_np(fname):
    raw = pd.read_csv(fname, iterator = True, chunksize = 25000, sep = ",")
    wholefile= pd.concat(raw,ignore_index=True)
    ret = np.asarray(wholefile.values, dtype = 'a5000')
    
    return ret


mpileup_data = get_mpileup_np('mpileup_small.csv')

df_mpileup = DataFrame(mpileup_data)

rbase = list(df_mpileup[2])
symbols = list(df_mpileup[4])
depth = list(df_mpileup[3])

#Calculate Indels for the file
indelcount = 0
for indels in symbols:
    if "-" in indels:
        indelcount += 1
    elif "+" in symbols:
        indelcount += 1
print "indelcount = ",indelcount

#Calculate SNPs for the file
countofnucleotides = 0
snpcount = 0
substitutioncount = 0


##count the number of A,C,T,G,a,c,t,g present in rbase
acount = 0
ccount = 0
tcount = 0
gcount = 0
bases = ["A", "C", "T", "G", "a", "c", "t", "g"]
for nucleotide in rbase:
    if nucleotide.lower() == 'a':
        acount += 1 
    elif nucleotide.lower() == 'c':
        ccount += 1
    elif nucleotide.lower() == 't':
        tcount +=1
    elif nucleotide.lower() == 'g':
        gcount +=1

print "substitutioncount = ",substitutioncount
print "snpcount = ",snpcount

#####Looking at rbase we should see much larger numbers (all of them seem to be in bases), additionally we should expect count of nucleotides to be the same length as bases (that is: have a count per base)#
#####snpcount will only be 1 if countofnecleotides is >= 1 and 0 otherwise (takes on no other values) (not sure if this in intentional)


             
#Extract the mapped reads present in the design file and the sequencing output file(reads)
mapped_reads = []        
for seq in refseq:
    for read in read_seq:
        if seq == read:
            mapped_reads.append(read)
print mapped_reads

#####Mapped_reads is missing some matches. I can't make sense of it logically, however when implementing my own version I found additional matches (which I verified)

#Compute the coverage of each sequence
haploidgenome_length = float(3*(10**9))##in basepairs;for human genome
read_length = 65
index = 0
for each in read_seq:
    print "depth per base = ",depth[index]
    index += 1
    
#write the data to a csv file    
"""
Modification History: 12/13/14
Author: Jeff Byrnes
Written By Alok Subbarao
Description: Transposes the output, previously each row was output as
a column
"""
data = [[ID, Name, refseq, Chromosome_Coordinates_designs, Mapping_quality_designs, read_seq, chromosome_coordinates ,Row, Column, Feature_number, indelcount, snpcount, substitutioncount, depth]]

out = pd.DataFrame(data[0][0:10])
fin = out.transpose()

fin.to_csv('sample_data.csv') ##instead of outputting the data I would use a key to how the data was subsetted
##for example d48685-92434s... (design rows 48685:92434, sam rows ...)

nxt = pd.DataFrame(data[0][10:13])
nxt.to_csv('count_for_sample.csv') ##I would include the key id in this output for logical data independence and clean comparisons later on

lst = pd.DataFrame(data[0][13])
lst.to_csv('depths_for_sample.csv') ##Again, key idre
